{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac9ab20-8a0e-45ca-b9ef-07acde5b1965",
   "metadata": {},
   "source": [
    "### Installation\n",
    "Install the packages required for executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "024614c9-4aa3-4ca5-9f9e-eef322903e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp>2\n",
      "  Downloading kfp-2.9.0.tar.gz (595 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.6/595.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[1 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --user --no-cache-dir --upgrade \"kfp>2\" \"google-cloud-pipeline-components>2\" \\\n",
    "                                        google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfc88a-c38e-45cc-90a5-3352f7ec8b8c",
   "metadata": {},
   "source": [
    "## Restart the kernel\n",
    "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75e2252-5e21-42fe-a558-c788d5dc6a60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9103be-54ed-4260-a5bf-0dea1ccde3f0",
   "metadata": {},
   "source": [
    "Check the versions of the packages you installed. The KFP SDK version should be >=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c27a22d-9371-4122-bba1-19cb83274755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'kfp'\n",
      "google-cloud-aiplatform==1.70.0\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'google_cloud_pipeline_components'\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c99b37-0d47-45ae-8aa4-523812273286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kfp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kfp'"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "import typing\n",
    "from typing import Dict\n",
    "from typing import NamedTuple\n",
    "from kfp import dsl\n",
    "from kfp.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d47f1-21f4-4414-907e-ad9e3898397f",
   "metadata": {},
   "source": [
    "#### Pipeline Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94faa2d8-89da-4bdd-a4a5-5cd82bd53ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The Google Cloud project that this pipeline runs in.\n",
    "PROJECT_ID = \"de2024-436414\"\n",
    "# The region that this pipeline runs in\n",
    "REGION = \"us-central1\"\n",
    "# Specify a Cloud Storage URI that your pipelines service account can access. The artifacts of your pipeline runs are stored within the pipeline root.\n",
    "PIPELINE_ROOT = \"gs://temp_de2024_17\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a85608-35c3-4879-bc3e-50efc8fc8427",
   "metadata": {},
   "source": [
    "#### Create the Components from Component Specifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccd22b7-af1a-48c6-b701-736e8fa71e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.container_component\n",
    "def data_ingestion(project: str, bucket: str, data_file_name: str,  features: Output[Artifact]): \n",
    "\n",
    "    return dsl.ContainerSpec(\n",
    "        image='us-central1-docker.pkg.dev/your project id/labrepo/dataingestor:0.0.1',\n",
    "        command=[\n",
    "            'python3', '/pipelines/component/src/component.py'\n",
    "        ],\n",
    "        args=['--project_id',project,'--bucket',bucket,'--file_name',data_file_name,'--feature_path', features.path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f079b57a-e305-420c-a47e-cbbedfe9b265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.container_component\n",
    "def mlp_training(project: str, features: Input[Artifact], model_bucket: str,  metrics: OutputPath(str)):\n",
    "    \n",
    "    return dsl.ContainerSpec(\n",
    "        image='us-central1-docker.pkg.dev/your project id/labrepo/mlptrainer:0.0.1',\n",
    "        command=[\n",
    "            'python3', '/pipelines/component/src/component.py'\n",
    "        ],\n",
    "        args=['--project_id',project,'--feature_path',features.path,'--model_repo',model_bucket,'--metrics_path', metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd09522-58a0-4414-95ef-54cc6a817c33",
   "metadata": {},
   "source": [
    "#### Define the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "226c8165-3459-4e43-b277-c35ba4a39316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the workflow of the pipeline.\n",
    "@kfp.dsl.pipeline(\n",
    "    name=\"student-predictor-mlp\")\n",
    "def pipeline(project_id: str, data_bucket: str, trainset_filename: str, model_repo: str):\n",
    "    \n",
    "    # The first step    \n",
    "    di_op = data_ingestion(\n",
    "        project=project_id,\n",
    "        bucket=data_bucket,\n",
    "        data_file_name=trainset_filename\n",
    "    )\n",
    "\n",
    "    # The second step \n",
    "    training_op = mlp_training(\n",
    "        project=project_id,\n",
    "        model_bucket=model_repo,       \n",
    "        features=di_op.outputs['features']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fba21b-eef1-4454-9809-625f22713117",
   "metadata": {},
   "source": [
    "#### Compile the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca3e726-654c-4a47-9088-08669d579844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp import compiler\n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='student_predictor_mlp.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699a5a5-2f9d-4519-8792-fdfcaeb4de26",
   "metadata": {},
   "source": [
    "#### Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de309748-04ad-4b18-9590-6b9d46fbcace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/diabetes-predictor-mlp-20241008202233?project=966204339179\n",
      "PipelineJob projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/966204339179/locations/us-central1/pipelineJobs/diabetes-predictor-mlp-20241008202233\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "# Before initializing, make sure to set the GOOGLE_APPLICATION_CREDENTIALS\n",
    "# environment variable to the path of your service account.\n",
    "aip.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    ")\n",
    "\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=\"student-predictor-mlp-pipeline\",\n",
    "    template_path=\"student_predictor_mlp.yaml\",\n",
    "    enable_caching=False,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        'project_id': PROJECT_ID,\n",
    "        'data_bucket': 'data_de2024_17', # makesure to use your data bucket name \n",
    "        'trainset_filename': 'training_set.csv',\n",
    "        'model_repo':'models_de2024_17' # makesure to use your model bucket name \n",
    "    }\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m84"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
